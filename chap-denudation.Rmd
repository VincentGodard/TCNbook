# Application to denudation rate measurements


```{r dm0, include=FALSE}
library("TCNtools")
```


## Concentration - denudation rate relationship

Now we are going to consider the evolution of concentration with denudation rate $\varepsilon$.
The computation will be carried out at the surface ($z=0$), but this could be done at any arbitrary depth.
We will consider that $t=+\infty$ and that we have reached the plateau concentration.
Equation \@ref(eq:conceuler) becomes,

\begin{equation}
C=\sum_i \frac{P_i}{\frac{\rho \varepsilon}{\Lambda_i}+\lambda} (\#eq:ssero)
\end{equation}

Which simplifies to $C\approx\frac{P_i \Lambda_i}{\rho \varepsilon}$ if we neglect radioactive decay.

We define the usual parameters.

```{r dm1}
altitude = 1000 # elevation in m
latitude = 45 # latitude in degrees
rho = 2.7
data(prm)
data(Lambda)
P = atm_pressure(alt=altitude,model="stone2000") # compute atmospheric pressure at site
S = scaling_st(P,latitude) # compute the scaling parameters according to Stone (2000)
```

Now compute the steady-state concentration for a range of denudation rates.

```{r dm2}
nuc = "Be10"
ero = 10^seq(log10(0.1),log10(1000),length.out = 100) * 100/1e6*rho # a log-spaced vector for denudation rate expressed in m/Ma and converted in g/cm2/a
age =  Inf # infinite age
z = 0 * rho # depth at which we are going to perform the calculation (cm converted to g/cm2)
C0 = 0 # inherited concentration
C = solv_conc_eul(z,ero,age,C0,prm[,nuc],S,Lambda) # compute concentration
```

We plot the result, and also consider consider the implications of neglecting the radioactive decay.

```{r dm3}
plot(ero/100*1e6/rho,C,col="lawngreen",log="xy",type="l",lwd=3,ylab="Concentration (at/g)",xlab="Denudation rate (m/Ma)")
# what happens if we neglect radioactive decay
Prod = c(prm[1,nuc]*S$Nneutrons,prm[2,nuc]*S$Nmuons,prm[3,nuc]*S$Nmuons) # scaled production vector (defined for the sake of clarity of the expressions)
lambda = prm[4,nuc] # radioactive decay
C2 = sum(Prod*Lambda)/ero
lines(ero/100*1e6/rho,C2,lty=2)
```

:::: {.codebox .codeimage data-latex="code"}
Below you can get all the necessary code to produce the figure
```{r eval=FALSE, class.source='fold-hide', include=TRUE, ref.label=c('dm0','dm1','dm2','dm3')}
```
::::


This figure (log-scales on both axes) highlights the strong inverse relationship, at steady-state, between denudation rate ($\varepsilon$) and concentration ($C$), which is the foundation of many geomorphological studies trying to establish landscape evolution rates.
Note the change in the relationship at very low denudation rates, which corresponds to the situation where the effects of radioactive decay become predominant.

:::: {.questionbox .questionimage data-latex="question"}
Over what range of denudation rates it is reasonable to neglect radioactive decay? What kind of geological context could it correspond to?
::::

A simple way to answer this question would be to compute the relative difference between the computed concentrations

```{r dm4}
error = abs(C-C2)/C*100
plot(ero/100*1e6/rho,error,log="xy",type="l",ylab="Relative error (%)",xlab="Denudation rate (m/Ma)")
```


## Catchment wide denudation rates
It can be noted that  when dealing with eroding bedrock surfaces the calculated denudation rate will be a very local estimate and that its extrapolation to longer wavelengths is only possible in the rather limited cases where the morphological properties of the relief are uniform over large distances (plateaus, morphological surfaces, etc ...). 
In reality, in complex environments, such as mountain ranges, where several processes contribute to denudation, a simple local estimate does not provide really useful information on the overall dynamics of the topography. 
An alternative approach is to use river sediments, which are a mixture of contributions from different parts of a watershed. 
The measurement of a cosmogenic nuclide concentration in this type of sample provides an estimate of the average denudation over the corresponding basin (@brown1995denudation,@granger1996spatially,@vonblanckenburg2005control).

Calculating such average denudation rate requires to obtain an average production rate for the catchment.
For low relief catchments the scaling parameters can be calculated using the average elevation of the catchment. But for catchments with several 1000s m in relief, the non linear relationship between the scaling parameters and elevation will make this approximation invalid.

We are going to explore these ideas using 3 basins from the study of @godard2012impact in the Marsyandi river basin (central Nepal)


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(sf)
library(leaflet)
bas0 <- st_read("data/gis/marsyandi.gpkg", quiet = TRUE)
bas <- st_transform(bas0, 4326)
centers <- st_centroid(bas)
xy = st_coordinates(centers)
m <- leaflet(bas) %>%
  addTiles() %>%
  addProviderTiles("OpenStreetMap",group = "OpenStreetMap") %>%
  addProviderTiles("Stamen.Terrain",group = "Stamen.Terrain") %>%
  addProviderTiles("Esri.WorldImagery",group = "Esri.WorldImagery") %>%
  addLayersControl(baseGroups = c("OpenStreetMap","Stamen.Terrain", "Esri.WorldImagery"),position = "topleft") %>%
  addPolygons() %>%
  addLabelOnlyMarkers(data = centers,
                    lng = xy[,1], lat = xy[,2], label = ~BASIN, 
                    labelOptions = labelOptions(noHide = TRUE, direction = 'auto', textOnly = FALSE)) 
m
```


Here are the maps for these 3 basins.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library("terra",verbose = F)
bas = vect("data/gis/marsyandi.gpkg")
layout(matrix(c(1,2,3), 1, 3, byrow = TRUE))
# plot ----
for (name in c("Khudi","Chudi","Marsyandi")){
dem = rast(paste0("data/gis/",name,".tif"))
slope <- terra::terrain(dem, "slope", unit="radians")
aspect <- terra::terrain(dem, "aspect", unit="radians")
hill <- terra::shade(slope, aspect, 40, 270)
plot(hill, col=grey(0:100/100), legend=FALSE,axes=F,main=name,mar=c(4, 2, 4, 4))
leg = terrain.colors(100,alpha=0.35)
plot(dem, col=leg, add=TRUE,axes=F,plg=list(cex=0.75),legend="bottomleft")
sbar(below="m",cex=0.9)
lines(bas)
}

```

We are going to load the corresponding data as dataframes (`x`, `y`, `z`), either from the disk or directly from the github repository (`path_to_data` indicates where to look for the data).

```{r dm5, eval=TRUE, include=FALSE}
path_to_data = "data/gis/"
#path_to_data ="https://raw.githubusercontent.com/VincentGodard/TCNbook/main/data/gis/" # we download directly from the github repository
names_basins = c("Marsyandi","Chudi","Khudi")
cols = c("deepskyblue", "khaki3", "darkolivegreen3")
basins = list() # we store the dataframe into a list object
for (i in 1:length(names_basins)){
  basins[[i]] = read.table(paste0(path_to_data,names_basins[i],".dat"),header=T)
}
```

```{r dm5b, eval=FALSE, include=TRUE}
#path_to_data = "data/gis/"
path_to_data ="https://raw.githubusercontent.com/VincentGodard/TCNbook/main/data/gis/" # we download directly from the github repository
names_basins = c("Marsyandi","Chudi","Khudi")
cols = c("deepskyblue", "khaki3", "darkolivegreen3")
basins = list() # we store the dataframe into a list object
for (i in 1:length(names_basins)){
  basins[[i]] = read.table(paste0(path_to_data,names_basins[i],".dat"),header=T)
}
```

We now plot the distribution of elevation for the 3 basins.



```{r dm6}
#
for (i in 1:length(names_basins)){
  if (i == 1){ # we initiate a plot at the first iteration
    plot(density(basins[[i]]$z),ylim=c(0,0.0022),xlab="Elevation (m)",col=cols[i],main="")
  }else{ # then add the following basins as lines on the initial plot
    lines(density(basins[[i]]$z),col=cols[i])
  }
}
legend("topright",names_basins,cex=0.5,lty=1,col=cols)
```

:::: {.questionbox .questionimage data-latex="question"}
Compare the distributions of elevation, and their position across the Himalayan range.
How is this going to impact the determination of an average production rate for the basin?
::::

We then compute the `st` scaling parameters for each pixel (lines in the dataframes).

```{r dm7}
for (i in 1:length(names_basins)){
basins[[i]]$P = atm_pressure(alt=basins[[i]]$z,model="stone2000") 
st = scaling_st(basins[[i]]$P,basins[[i]]$y)
basins[[i]] = cbind(basins[[i]],st)
}
```

We plot the distribution of the spallation scaling factor for each basin.

```{r dm8}
# plotting result
for (i in 1:length(names_basins)){
  if (i == 1){ # we initiate a plot at the first iteration
    plot(density(basins[[i]]$Nneutrons),ylim=c(1e-4,2.5),xlab="Spallation scaling factor",col=cols[i],main="",log="y")
  }else{
    lines(density(basins[[i]]$Nneutrons),col=cols[i])
  }
}
legend("topright",names_basins,cex=0.5,lty=1,col=cols)
```
We now compute average values for the scaling paramters, in 2 different ways,

- **1** : We compute the scaling at each pixel according to its latitude and altitude (as we did above), and then take the average over the basin
- **2** : we compute the average latitude and altitude of the basin, and then use these average values to compute the scaling factors

We create a dataframe `res` to store the results.

```{r dm9}
res = data.frame(names=names_basins) # dataframe to store the results
res$S1 = NA
res$S2 = NA
res$relief = NA
for (i in 1:nrow(res)){
  res$relief[i] = max(basins[[i]]$z) - min(basins[[i]]$z)
  #
  res$S1[i] = mean(basins[[i]]$Nneutrons)
  #
  P2 = atm_pressure(alt=mean(basins[[i]]$z),model="stone2000") 
  st = scaling_st(P2,mean(basins[[i]]$y))
  res$S2[i] = st$Nneutrons
}
print(res)
```
We can visualize the difference between the two approaches.

```{r dm10}
plot(res$S2,res$S1,pch=21,bg=cols,
     xlab="S2 : Scaling from average elevation",ylab="S1 : Scaling pixel by pixel",
     xlim=range(0,res$S2,res$S1),ylim=range(0,res$S2,res$S1))
grid()
text(res$S2,res$S1,res$names,cex=0.5,pos=1)
abline(0,1,lty=2)

```

:::: {.codebox .codeimage data-latex="code"}
Below you can get all the necessary code to produce the figures presented in this section
```{r eval=FALSE, class.source='fold-hide', include=TRUE, ref.label=c('dm0','dm5b','dm6','dm7','dm8','dm9','dm10')}
```
::::

:::: {.questionbox .questionimage data-latex="question"}
- Comment on the differences. 
- What are the other parameters which can influence the calculation of average production rates at the scale of a basin?
::::





## Calculation of denudation rates

We are going to load a subset of the octopus database from @codilean2022octopus, which compile most of the published catchment-wide denudation rates and can be accessed through this web site :

[https://octopusdata.org](https://octopusdata.org) 

The original database have been filtered to retain catchments with the following characteristics

- Area in the 20-100 km$^2$ range
- Denudation rate $<$ 2 mm/a

```{r dm50, eval=TRUE, include=FALSE}
octopus = read.table("data/gis/octopus.dat",header=T)
```

```{r dm50b, eval=FALSE, include=TRUE}
octopus = read.table("https://raw.githubusercontent.com/VincentGodard/TCNbook/main/data/gis/octopus.dat",header=T)
```

The data base contains a lot of information about the catchments.

```{r}
octopus
```

We can have look at the distribution of these denudation rates.

```{r dm50c}
hist(octopus$EBE_MMKYR,breaks=50,xlab="Denudation rate (mm/ka)",main="")
```

We can first make a very crude calculation, considering only production by neutrons and neglecting radioactive decay, using the following relationship,

$$\varepsilon=\frac{P \Lambda}{\rho C}$$
We load the usual parameters and make some definitions

```{r dm51}
data(Lambda)
data(prm)
rho = 2.65 # same density in g/cm3 as the one used in Octopus
```

We compute the scaling factors for each basin, using its average elevation to compute average scaling factors. 
This is a very important point and a section will be devoted to the analysis of this approximation.

```{r dm52}
octopus$P = atm_pressure(alt=octopus$ELEV_AVE,model="stone2000")
S = scaling_st(octopus$P,octopus$Y_WGS84)
octopus = cbind(octopus,S)
```

For the sake of readability we define a number of variables.

```{r dm53}
Pspal = prm["Pspal","Be10"]*octopus$Nneutrons # scaled spallation production rate
Pstop = prm["Pstop","Be10"]*octopus$Nmuons # scalled stopped muons production rate
Pfast = prm["Pfast","Be10"]*octopus$Nmuons # scalled fast muons production rate
lambda = prm["lambda","Be10"]
C = octopus$BE10NC
```

We can now compute denudation rates and compare them with the rates calculated in Octopus.

```{r dm54}
octopus$E1 = (Pspal*Lambda[1])/(rho*C)*10*1000 # denudation rate in mm/ka
plot(octopus$EBE_MMKYR,octopus$E1,pch=21,bg="lightblue",cex=0.5,
     xlab="Octopus denudation rate (mm/ka)",ylab="Recalculated denudation rate (mm/ka)")
abline(0,1,col="red",lty=2)
```

:::: {.questionbox .questionimage data-latex="question"}
What can you say about this comparison?
::::

We compute an estimator of the difference for latter reference.

```{r dm55}
ER1 = mean(((octopus$EBE_MMKYR-octopus$E1)/octopus$EBE_MMKYR)^2)
ER1
```

Now we include muons in the calculation (still neglecting radioactive decay):
$$ \varepsilon=\sum_i \frac{P_i\Lambda_i}{\rho C}$$

```{r dm56}
octopus$E2 = (Pspal*Lambda[1] + Pstop*Lambda[2] + Pfast*Lambda[3])/(rho*C)*10*1000
plot(octopus$EBE_MMKYR,octopus$E2,pch=21,bg="lightblue",cex=0.5,
     xlab="Octopus denudation rate (mm/ka)",ylab="Recalculated denudation rate (mm/ka)")
abline(0,1,col="red",lty=2)
```

```{r dm57}
ER2 = mean(((octopus$EBE_MMKYR-octopus$E2)/octopus$EBE_MMKYR)^2)
ER2
```


:::: {.questionbox .questionimage data-latex="question"}
Comment on the differences between the two calculations.
::::

The denudation rates span several orders of magnitude, so we use a log-log plot.


```{r dm58}
plot(octopus$EBE_MMKYR,octopus$E2,log="xy",pch=21,bg="lightblue",cex=0.5)
abline(0,1,col="red",lty=2)
```

:::: {.questionbox .questionimage data-latex="question"}
What happens for low denudation rates?
::::

Now we want to take into account radioactive decay, and have to deal with equation \@ref(eq:ssero), which does not allow to compute denudation rate $\varepsilon$ directly.
So we have to solve $C_{mod}(\varepsilon) = C_{obs}$.
For that purpose we define a function to compute concentration for any value of $\varepsilon$, and a function to optimize the difference between the modeled and observed concentration : $|C_{mod}(\varepsilon) - C_{obs}|$.


```{r dm59}
compute_C <- function(ero,prm,S,Lambda){
  C = solv_conc_eul(0,ero,Inf,0,prm,S,Lambda) # compute concentration
  return(C)
}
fun_opt <-function(ero,prm,S,Lambda,Cmes){
  Cmod =  compute_C(ero,prm,S,Lambda)
  return(abs(Cmod-Cmes))
}
```

Then we run the optimization for each basin.

```{r dm60}
octopus$E3 = NA
for (i in 1:nrow(octopus)){
  res = optimize(fun_opt,c(0,3000)/10*rho,prm[,"Be10"],c(octopus$Nneutrons[i],octopus$Nmuons[i]),
                 Lambda,octopus$BE10NC[i])
  octopus$E3[i] = res$minimum*10/rho*1000
}
```


And we compare again the denudation rates.

```{r dm61}
plot(octopus$EBE_MMKYR,octopus$E3,log="xy",pch=21,bg="lightblue",cex=0.5)
abline(0,1,col="red",lty=2)
```

```{r dm62}
ER3 = mean(((octopus$EBE_MMKYR-octopus$E3)/octopus$EBE_MMKYR)^2)
ER3
```


:::: {.questionbox .questionimage data-latex="question"}
Comment this result. What additional modifications could we think of to refine our calculation of denudation rates? 
::::

:::: {.codebox .codeimage data-latex="code"}
Below you can get all the necessary code to produce these figures
```{r eval=FALSE, class.source='fold-hide', include=TRUE, ref.label=c('dm50b','dm50c','dm51','dm52','dm53','dm54','dm55','dm56','dm57','dm58','dm59','dm60','dm61','dm62')}
```
::::




## Integration time scale
Like all techniques used to measure erosion or denudation of the Earth surface, rates measured from cosmogenic nuclides are averaged over a specific period of time.
This integration time-scale is often considered, at first order, to be the time required to erode the thickness of the zone where most of nuclide production  occurs (@vonblanckenburg2005control), which can be considered as the penetration length for neutrons $\Lambda/\rho$. 
This average is one of the advantages of the method, allowing to filter the high frequency variability, in particular of anthropic origin (@reusser2015quantifying). 

In its simplest form the integration time scale $\tau$ for a denudation rate measurement can be calculated as,
\begin{equation}
\tau = \frac{\Lambda}{\rho \varepsilon} 
\end{equation}


```{r}
rho = 2.7
data(Lambda)
ero = 10^seq(log10(0.5),log10(2000),length.out = 100) # log spaced vector for denudation rate mm/ka
tau = (Lambda[1]/rho*10)/ero
plot(ero,tau,xlab="Denudation rate (mm/ka)",ylab="Integration time scale (ka)",type="l",log="xy",lwd=3,col="gold")
```

This simple plot allows to observe the very strong influence of denudation rate $\varepsilon$ on the integration time scale.

- For a denudation rate of 10 mm/ka, typical of slow erosion cratonic domains, the integration time scale is ~60 ka
- For a denudation rate of 500 mm/ka, which can be encountered in high relief mountain ranges, the integration time scale is ~1 ka

:::: {.questionbox .questionimage data-latex="question"}
What are the implications of this relationship for the geomorphological interpretation of the denudation rates?
::::



## Change in denudation through time

The  `solv_conc_eul` function has a `in_ero` parameter which allows to specify an initial denudation rate, and then simulate the evolution concentration as a response to a change in the denudation rate.

```{r dm11}
altitude = 1000 # elevation in m
latitude = 45 # latitude in degrees
P = atm_pressure(alt=altitude,model="stone2000") # compute atmospheric pressure at site
S = scaling_st(P,latitude) # compute the scaling parameters according to Stone (2000)
rho = 2.7
#
nuc = "Be10"
E1 = 10/1.e6*100*rho # denudation rate conversion en m/Ma -> g/cm2/a
E2 = 20/1.e6*100*rho # denudation rate conversion en m/Ma -> g/cm2/a
t = seq(0,1e6,length.out = 10000)
C = solv_conc_eul(0,E2,t,0,prm[,nuc],S,Lambda,in_ero=E1)
plot(t/1e6,C,xlab="Time (Ma)",ylab="Concentration (at/g)",type="l",col="gold",lwd=2)
```

:::: {.codebox .codeimage data-latex="code"}
Below you can get all the necessary code to produce the figure
```{r eval=FALSE, class.source='fold-hide', include=TRUE, ref.label=c('dm0','dm11')}
```
::::


:::: {.actionbox .actionimage data-latex="action"}
- Change the values of the denudation rates `E1` and `E2`
- Change the nuclide (use "Al26" and "C14")
::::

:::: {.questionbox .questionimage data-latex="question"}
- What are the implications of changes in denudation rates for the interpretation of TCN concentrations?
- What kind of geomorphological situation could it correspond to?
- Further reading for the $^{14}$C/$^{10}$Be system in @mudd2016detection. What kinf of information does the use of multiple nuclides can provide?
::::

You can also explore dynamically the impact of changes in denudation rates  using this embedded application, which use the same type of code. 

```{r echo=FALSE}
knitr::include_url("https://shinyproxy.osupytheas.fr/transient_erosion/",height = "1200px")
```


## On the importance of muons

For $^{10}$Be the muonic contribution represents a very small fraction of surface production : 

```{r dm20}
nuc = "Be10"
f = (prm[2,nuc]+prm[3,nuc])/sum(prm[1:3,nuc])*100
paste("For",nuc,"muons represent",round(f,1),"% of SLHL surface production")
```

Muons provide a a very small fraction of production at the surface for $^{10}$Be, but they penetrate much deeper than neutrons into rocks. 
For that reason they are going to account to a higher proportion of nuclides on eroding surfaces.
We can separate the various sources of production (neutrons and muons) and see what is their respective contributions to the concentration observed at the surface.


```{r dm21}
col_sp = "deepskyblue"
col_sm = "indianred1"
col_fm = "darkseagreen1"
nuc = "Be10"
data = data.frame(ero1=10^seq(log10(0.1),log10(2000),length=100)) # ero1 -> denudation in m/Ma
emin = min(data$ero1)
emax = max(data$ero1)
data$ero2 = data$ero1/1e6*100*rho # ero2 = denudation in g/cm2/a
# steady state concentrations associated with individual production pathways
data$Csp = prm[1,nuc]*S$Nneutrons/(prm[4,nuc]+(data$ero2/Lambda[1]))
data$Csm = prm[2,nuc]*S$Nmuons/(prm[4,nuc]+(data$ero2/Lambda[2]))
data$Cfm = prm[3,nuc]*S$Nmuons/(prm[4,nuc]+(data$ero2/Lambda[3]))
data$C = data$Csp + data$Csm + data$Cfm
#
plot(NA,xlim=c(emin,emax),ylim=c(0,1),log="x",xlab="Denudation rate (m/Ma)",ylab="Fraction",xaxs="i",yaxs="i")
polygon(c(emin,emax,emax,emin),c(0,0,1,1),col=col_fm)
polygon(c(emin,emax,rev(data$ero1)),
        c(0,0,rev((data$Csp+data$Csm)/data$C)),col=col_sm)
polygon(c(emin,emax,rev(data$ero1)),
        c(0,0,rev(data$Csp/data$C)),col=col_sp)
grid(col="black",equilogs = FALSE)
#
text(0.2,0.1,nuc,cex=2)
legend("bottomright",
       c("Spallation","Stopping muons","Fast muons"),
       pch=22,pt.bg=c(col_sp,col_sm,col_fm),pt.cex=1.5,cex=1,bg="white")
```

:::: {.codebox .codeimage data-latex="code"}
Below you can get all the necessary code to produce the figure
```{r eval=FALSE, class.source='fold-hide', include=TRUE, ref.label=c('dm0','dm1','dm21')}
```
::::


